{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unsupervized.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr_HXHlfQYmc",
        "outputId": "b199dece-f5f2-4f72-ee7b-499c5c44cfa8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW8Sxcgn1r4-"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/random_sample_astan.csv\")\n",
        "\n",
        "question = df.iloc[:, 1].tolist()\n",
        "answer = df['پاسخ'].tolist()\n",
        "answer\n",
        "data = []\n",
        "x = \"\"\n",
        "\n",
        "for i in range(len(question)):\n",
        "  # x += answer[i]\n",
        "  x += str(question[i])\n",
        "  data.append(x)\n",
        "  x = \"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ3_OpZ4KZdH"
      },
      "source": [
        "#  seprate 80% of data for train\n",
        "train_data = data[:40000]\n",
        "\n",
        "#  seprate 20% data for test\n",
        "test_data = data[40000:46579]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fduz0PBydr1"
      },
      "source": [
        "#  stop words\n",
        "SW = []\n",
        " \n",
        "with open('/content/drive/My Drive/verbal') as file :\n",
        "  for line in file :\n",
        "    SW.append(line)\n",
        "\n",
        "with open('/content/drive/My Drive/short') as file :\n",
        "  for line in file :\n",
        "    SW.append(line)\n",
        "\n",
        "with open('/content/drive/My Drive/persian') as file :\n",
        "  for line in file :\n",
        "    SW.append(line)\n",
        "\n",
        "with open('/content/drive/My Drive/nonverbal') as file :\n",
        "  for line in file :\n",
        "    SW.append(line)\n",
        "\n",
        "SW = [ s.replace('\\n' , '') for s in SW]\n",
        "SW = list(set(SW))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy7m2eGhrzZH"
      },
      "source": [
        "#####################\n",
        "#  BOW\n",
        "#####################\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "CountVec = CountVectorizer(stop_words= SW)\n",
        "vec = CountVec.fit(train_data)\n",
        "vectorized = vec.transform(train_data)\n",
        "\n",
        "number_of_clusters= 3\n",
        "kmeans = KMeans(n_clusters=number_of_clusters, max_iter = 50)\n",
        "kmeans.fit(vectorized)\n",
        "\n",
        "print(\"Top terms per cluster:\")\n",
        "order_centroids = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vec.get_feature_names()\n",
        "\n",
        "for i in range(number_of_clusters):\n",
        "    top_ten_words = [terms[ind] for ind in order_centroids[i, :10]]\n",
        "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kY5RjzMFUlqv",
        "outputId": "4492eae3-7e3b-4a6b-9360-bb5a6755dbdc"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "score = silhouette_score(vectorized, kmeans.labels_, metric= 'euclidean')\n",
        "print(\" best score of  BOW classification train data :\")\n",
        "score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " best score of  BOW classification train data :\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03289788133115093"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNjYUxeKPHNI"
      },
      "source": [
        "results_train = pd.DataFrame({\n",
        "    'text': train_data[:20],\n",
        "    'category': kmeans.labels_[:20]\n",
        "})\n",
        "\n",
        "print(\"20 first data in train data with cluster number:\")\n",
        "\n",
        "list_train = results_train.values.tolist()\n",
        "\n",
        "for i in range(len(list_train)):\n",
        "  print(data[i], list_train[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni04dPeyPVoY"
      },
      "source": [
        "vec_test = vec.transform(test_data)\n",
        "kmeans.predict(vec_test)\n",
        "\n",
        "print(\"20 first data in test data with cluster number:\")\n",
        "results_test = pd.DataFrame({\n",
        "    'text': test_data[:20],\n",
        "    'category': kmeans.labels_[:20]\n",
        "})\n",
        "\n",
        "list_test = results_test.values.tolist()\n",
        "\n",
        "for i in range(len(list_test)):\n",
        "  print(data[i+40000], list_test[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jQE8mHBop-y"
      },
      "source": [
        "#####################\n",
        "#  tfidf\n",
        "#####################\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words= SW)\n",
        "vec = vectorizer.fit(train_data)   \n",
        "vectorized = vec.transform(train_data) \n",
        "\n",
        "number_of_clusters= 20\n",
        "km = KMeans(n_clusters=number_of_clusters)\n",
        "# Normally people fit the matrix\n",
        "km.fit(vectorized)\n",
        "\n",
        "print(\"Top terms per cluster:\")\n",
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
        "terms = vec.get_feature_names()\n",
        "\n",
        "for i in range(number_of_clusters):\n",
        "    top_ten_words = [terms[ind] for ind in order_centroids[i, :10]]\n",
        "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbspyrXeaLTI",
        "outputId": "6c2e3527-227a-4348-84eb-6f66fe843d1d"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "score = silhouette_score(vectorized, km.labels_, metric= 'euclidean')\n",
        "print(\" best score of classification tfidf:\")\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " best score of classification tfidf:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.007931652095494445"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d7cO448M7CV"
      },
      "source": [
        "results_train = pd.DataFrame({\n",
        "    'text': train_data[:20],\n",
        "    'category': km.labels_[:20]\n",
        "})\n",
        "\n",
        "print(\"20 first data in train data with cluster number:\")\n",
        "\n",
        "list_train = results_train.values.tolist()\n",
        "\n",
        "for i in range(len(list_train)):\n",
        "  print(data[i], list_train[i][1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uN2tzIULsH5"
      },
      "source": [
        "print(\"20 first data in test data with cluster number:\")\n",
        "\n",
        "list2Vec = vec.transform(test_data)\n",
        "km.predict(list2Vec)\n",
        "\n",
        "results_test = pd.DataFrame({\n",
        "    'text': test_data[:20],\n",
        "    'category': km.labels_[:20]\n",
        "})\n",
        "\n",
        "list_test = results_test.values.tolist()\n",
        "\n",
        "for i in range(len(list_test)):\n",
        "  print(data[i+40000], list_test[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMT7gHwPW2Em"
      },
      "source": [
        "!git clone https://github.com/facebookresearch/fastText.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D00quZ9WW9JL"
      },
      "source": [
        "!cd fastText\n",
        "!pip install fastText"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9MlKsZok9lY"
      },
      "source": [
        "#####################\n",
        "#  fasttext\n",
        "#####################\n",
        "\n",
        "fasttext.util.download_model('fa', if_exists='ignore')  # English\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q87l5OrDgul4"
      },
      "source": [
        "import fasttext.util\n",
        "import fasttext\n",
        "ft = fasttext.load_model('cc.fa.300.bin')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOOCZdrgIg37"
      },
      "source": [
        "list_vect = []\n",
        "for i in range(len(train_data)):\n",
        "  vect = ft.get_sentence_vector(train_data[i]) # 1 sentence\n",
        "  list_vect.append(vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QTBreFbR0rG"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "number_of_clusters= 3\n",
        "km = KMeans(n_clusters=number_of_clusters)\n",
        "km.fit(list_vect)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73cbsr3aw0WH"
      },
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "score = silhouette_score(list_vect, km.labels_, metric= 'euclidean')\n",
        "print(\"best score of classification fast text for train data:\")\n",
        "score\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrPbX1dcXETj"
      },
      "source": [
        "list_vect_test = []\n",
        "for i in range(len(test_data)):\n",
        "  vect = ft.get_sentence_vector(test_data[i]) \n",
        "  list_vect_test.append(vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW1_EtpMXzwo"
      },
      "source": [
        "km.predict(list_vect_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}